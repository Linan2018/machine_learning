{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ch4_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4bIBqoSXbUj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5e3881ba-f3cc-40af-f79f-33eaf6f1e8dd"
      },
      "source": [
        "cd drive/My\\ Drive/ML_hw"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ML_hw\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azwfaro6XmOD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "591d6162-2811-4c17-e6ea-696273e98141"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/ML_hw'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r6hl_XQmW9h5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation\n",
        "from keras.optimizers import SGD,Adam\n",
        "\n",
        "np.random.seed(0)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhxZqqIS_Yr6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "92a1ef10-cd33-496a-bb0e-a0be23c9c8e3"
      },
      "source": [
        "df = pd.read_csv('forestfires.csv')\n",
        "df"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>86.2</td>\n",
              "      <td>26.2</td>\n",
              "      <td>94.3</td>\n",
              "      <td>5.1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>51</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>oct</td>\n",
              "      <td>tue</td>\n",
              "      <td>90.6</td>\n",
              "      <td>35.4</td>\n",
              "      <td>669.1</td>\n",
              "      <td>6.7</td>\n",
              "      <td>18.0</td>\n",
              "      <td>33</td>\n",
              "      <td>0.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>oct</td>\n",
              "      <td>sat</td>\n",
              "      <td>90.6</td>\n",
              "      <td>43.7</td>\n",
              "      <td>686.9</td>\n",
              "      <td>6.7</td>\n",
              "      <td>14.6</td>\n",
              "      <td>33</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>mar</td>\n",
              "      <td>fri</td>\n",
              "      <td>91.7</td>\n",
              "      <td>33.3</td>\n",
              "      <td>77.5</td>\n",
              "      <td>9.0</td>\n",
              "      <td>8.3</td>\n",
              "      <td>97</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>6</td>\n",
              "      <td>mar</td>\n",
              "      <td>sun</td>\n",
              "      <td>89.3</td>\n",
              "      <td>51.3</td>\n",
              "      <td>102.2</td>\n",
              "      <td>9.6</td>\n",
              "      <td>11.4</td>\n",
              "      <td>99</td>\n",
              "      <td>1.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>27.8</td>\n",
              "      <td>32</td>\n",
              "      <td>2.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.44</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.9</td>\n",
              "      <td>71</td>\n",
              "      <td>5.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>54.29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>aug</td>\n",
              "      <td>sun</td>\n",
              "      <td>81.6</td>\n",
              "      <td>56.7</td>\n",
              "      <td>665.6</td>\n",
              "      <td>1.9</td>\n",
              "      <td>21.2</td>\n",
              "      <td>70</td>\n",
              "      <td>6.7</td>\n",
              "      <td>0.0</td>\n",
              "      <td>11.16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>aug</td>\n",
              "      <td>sat</td>\n",
              "      <td>94.4</td>\n",
              "      <td>146.0</td>\n",
              "      <td>614.7</td>\n",
              "      <td>11.3</td>\n",
              "      <td>25.6</td>\n",
              "      <td>42</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>nov</td>\n",
              "      <td>tue</td>\n",
              "      <td>79.5</td>\n",
              "      <td>3.0</td>\n",
              "      <td>106.7</td>\n",
              "      <td>1.1</td>\n",
              "      <td>11.8</td>\n",
              "      <td>31</td>\n",
              "      <td>4.5</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     X  Y month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain   area\n",
              "0    7  5   mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0   0.00\n",
              "1    7  4   oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0   0.00\n",
              "2    7  4   oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0   0.00\n",
              "3    8  6   mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2   0.00\n",
              "4    8  6   mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0   0.00\n",
              "..  .. ..   ...  ...   ...    ...    ...   ...   ...  ..   ...   ...    ...\n",
              "512  4  3   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0   6.44\n",
              "513  2  4   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  54.29\n",
              "514  7  4   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  11.16\n",
              "515  1  4   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0   0.00\n",
              "516  6  3   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0   0.00\n",
              "\n",
              "[517 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5i-3vXdP_d_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mon = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
        "df = df.drop(['day'],axis=1)\n",
        "for i, m in enumerate(mon):\n",
        "  df = df.replace(m, i)\n",
        "df = df.apply(pd.to_numeric, errors='ignore')\n",
        "df = (df - df.mean()) / (df.std()) "
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieHfmBzVFTvQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "cd33b685-0a2b-4fff-bd43-5716222acac9"
      },
      "source": [
        "df"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>month</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.007337</td>\n",
              "      <td>0.569309</td>\n",
              "      <td>-1.966538</td>\n",
              "      <td>-0.805180</td>\n",
              "      <td>-1.322045</td>\n",
              "      <td>-1.828706</td>\n",
              "      <td>-0.860113</td>\n",
              "      <td>-1.840857</td>\n",
              "      <td>0.411326</td>\n",
              "      <td>1.497164</td>\n",
              "      <td>-0.073197</td>\n",
              "      <td>-0.201824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.007337</td>\n",
              "      <td>-0.243765</td>\n",
              "      <td>1.109046</td>\n",
              "      <td>-0.008094</td>\n",
              "      <td>-1.178399</td>\n",
              "      <td>0.488418</td>\n",
              "      <td>-0.509195</td>\n",
              "      <td>-0.153130</td>\n",
              "      <td>-0.691786</td>\n",
              "      <td>-1.740070</td>\n",
              "      <td>-0.073197</td>\n",
              "      <td>-0.201824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.007337</td>\n",
              "      <td>-0.243765</td>\n",
              "      <td>1.109046</td>\n",
              "      <td>-0.008094</td>\n",
              "      <td>-1.048806</td>\n",
              "      <td>0.560173</td>\n",
              "      <td>-0.509195</td>\n",
              "      <td>-0.738668</td>\n",
              "      <td>-0.691786</td>\n",
              "      <td>-1.516813</td>\n",
              "      <td>-0.073197</td>\n",
              "      <td>-0.201824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.439531</td>\n",
              "      <td>1.382383</td>\n",
              "      <td>-1.966538</td>\n",
              "      <td>0.191177</td>\n",
              "      <td>-1.211188</td>\n",
              "      <td>-1.896429</td>\n",
              "      <td>-0.004751</td>\n",
              "      <td>-1.823636</td>\n",
              "      <td>3.230391</td>\n",
              "      <td>-0.009824</td>\n",
              "      <td>0.602572</td>\n",
              "      <td>-0.201824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.439531</td>\n",
              "      <td>1.382383</td>\n",
              "      <td>-1.966538</td>\n",
              "      <td>-0.243597</td>\n",
              "      <td>-0.930142</td>\n",
              "      <td>-1.796859</td>\n",
              "      <td>0.126843</td>\n",
              "      <td>-1.289763</td>\n",
              "      <td>3.352959</td>\n",
              "      <td>-1.237741</td>\n",
              "      <td>-0.073197</td>\n",
              "      <td>-0.201824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>-0.289244</td>\n",
              "      <td>-1.056839</td>\n",
              "      <td>0.230308</td>\n",
              "      <td>-1.638496</td>\n",
              "      <td>-0.845829</td>\n",
              "      <td>0.474309</td>\n",
              "      <td>-1.561947</td>\n",
              "      <td>1.534597</td>\n",
              "      <td>-0.753070</td>\n",
              "      <td>-0.735411</td>\n",
              "      <td>-0.073197</td>\n",
              "      <td>-0.100655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>-1.153631</td>\n",
              "      <td>-0.243765</td>\n",
              "      <td>0.230308</td>\n",
              "      <td>-1.638496</td>\n",
              "      <td>-0.845829</td>\n",
              "      <td>0.474309</td>\n",
              "      <td>-1.561947</td>\n",
              "      <td>0.518517</td>\n",
              "      <td>1.637006</td>\n",
              "      <td>0.994835</td>\n",
              "      <td>-0.073197</td>\n",
              "      <td>0.651044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>1.007337</td>\n",
              "      <td>-0.243765</td>\n",
              "      <td>0.230308</td>\n",
              "      <td>-1.638496</td>\n",
              "      <td>-0.845829</td>\n",
              "      <td>0.474309</td>\n",
              "      <td>-1.561947</td>\n",
              "      <td>0.397965</td>\n",
              "      <td>1.575722</td>\n",
              "      <td>1.497164</td>\n",
              "      <td>-0.073197</td>\n",
              "      <td>-0.026506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>-1.585825</td>\n",
              "      <td>-0.243765</td>\n",
              "      <td>0.230308</td>\n",
              "      <td>0.680298</td>\n",
              "      <td>0.548471</td>\n",
              "      <td>0.269122</td>\n",
              "      <td>0.499693</td>\n",
              "      <td>1.155720</td>\n",
              "      <td>-0.140230</td>\n",
              "      <td>-0.009824</td>\n",
              "      <td>-0.073197</td>\n",
              "      <td>-0.201824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>0.575144</td>\n",
              "      <td>-1.056839</td>\n",
              "      <td>1.548415</td>\n",
              "      <td>-2.018923</td>\n",
              "      <td>-1.684282</td>\n",
              "      <td>-1.778719</td>\n",
              "      <td>-1.737406</td>\n",
              "      <td>-1.220876</td>\n",
              "      <td>-0.814354</td>\n",
              "      <td>0.269248</td>\n",
              "      <td>-0.073197</td>\n",
              "      <td>-0.201824</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>517 rows × 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            X         Y     month  ...      wind      rain      area\n",
              "0    1.007337  0.569309 -1.966538  ...  1.497164 -0.073197 -0.201824\n",
              "1    1.007337 -0.243765  1.109046  ... -1.740070 -0.073197 -0.201824\n",
              "2    1.007337 -0.243765  1.109046  ... -1.516813 -0.073197 -0.201824\n",
              "3    1.439531  1.382383 -1.966538  ... -0.009824  0.602572 -0.201824\n",
              "4    1.439531  1.382383 -1.966538  ... -1.237741 -0.073197 -0.201824\n",
              "..        ...       ...       ...  ...       ...       ...       ...\n",
              "512 -0.289244 -1.056839  0.230308  ... -0.735411 -0.073197 -0.100655\n",
              "513 -1.153631 -0.243765  0.230308  ...  0.994835 -0.073197  0.651044\n",
              "514  1.007337 -0.243765  0.230308  ...  1.497164 -0.073197 -0.026506\n",
              "515 -1.585825 -0.243765  0.230308  ... -0.009824 -0.073197 -0.201824\n",
              "516  0.575144 -1.056839  1.548415  ...  0.269248 -0.073197 -0.201824\n",
              "\n",
              "[517 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGghiNWzC9I-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = np.array(df, dtype=np.float64)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06WN5OJCDLHP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "ed5b9c07-410a-41d9-e5b5-8f2d79c6f8f4"
      },
      "source": [
        "data"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.00733714,  0.56930904, -1.96653837, ...,  1.49716438,\n",
              "        -0.07319742, -0.20182432],\n",
              "       [ 1.00733714, -0.24376492,  1.10904606, ..., -1.74007034,\n",
              "        -0.07319742, -0.20182432],\n",
              "       [ 1.00733714, -0.24376492,  1.10904606, ..., -1.51681277,\n",
              "        -0.07319742, -0.20182432],\n",
              "       ...,\n",
              "       [ 1.00733714, -0.24376492,  0.23030765, ...,  1.49716438,\n",
              "        -0.07319742, -0.02650649],\n",
              "       [-1.58582453, -0.24376492,  0.23030765, ..., -0.0098242 ,\n",
              "        -0.07319742, -0.20182432],\n",
              "       [ 0.57514353, -1.05683889,  1.54841526, ...,  0.26924776,\n",
              "        -0.07319742, -0.20182432]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRSZv6GJD07_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "8c23b448-aee4-4a9a-8a26-d51e2c1b5650"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Dense(256, input_dim=x.shape[1], activation='tanh'))\n",
        "model.add(Dense(256, activation='tanh'))\n",
        "model.add(Dense(128, activation='tanh'))\n",
        "model.add(Dense(1, activation='tanh'))\n",
        " \n",
        "sgd = SGD(lr=0.001, decay=1e-6)\n",
        "model.compile(loss='mse', optimizer=sgd)\n",
        "print(model.summary())"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_69 (Dense)             (None, 256)               3072      \n",
            "_________________________________________________________________\n",
            "dense_70 (Dense)             (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_71 (Dense)             (None, 128)               32896     \n",
            "_________________________________________________________________\n",
            "dense_72 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 101,889\n",
            "Trainable params: 101,889\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2OqGqboBd_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d9f4ab94-278c-470b-fe75-92776af72fa6"
      },
      "source": [
        "random.shuffle(data)\n",
        "x, y = data[:, :-1], data[:, -1].reshape((data.shape[0], 1))\n",
        "\n",
        "history = model.fit(x, y, validation_split=0.8, epochs=100, batch_size=16)\n",
        "\n",
        "epochs=range(len(history.history['loss']))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs,history.history['loss'],'b',label='Training loss')\n",
        "plt.plot(epochs,history.history['val_loss'],'r',label='Validation val_loss')\n",
        "plt.title('Traing and Validation loss')\n",
        "plt.legend()\n",
        "plt.savefig('4_2.svg')"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 103 samples, validate on 414 samples\n",
            "Epoch 1/100\n",
            "103/103 [==============================] - 0s 881us/step - loss: 0.1051 - val_loss: 0.1203\n",
            "Epoch 2/100\n",
            "103/103 [==============================] - 0s 376us/step - loss: 0.0687 - val_loss: 0.0836\n",
            "Epoch 3/100\n",
            "103/103 [==============================] - 0s 378us/step - loss: 0.0465 - val_loss: 0.0552\n",
            "Epoch 4/100\n",
            "103/103 [==============================] - 0s 459us/step - loss: 0.0305 - val_loss: 0.0365\n",
            "Epoch 5/100\n",
            "103/103 [==============================] - 0s 380us/step - loss: 0.0195 - val_loss: 0.0229\n",
            "Epoch 6/100\n",
            "103/103 [==============================] - 0s 431us/step - loss: 0.0118 - val_loss: 0.0145\n",
            "Epoch 7/100\n",
            "103/103 [==============================] - 0s 400us/step - loss: 0.0072 - val_loss: 0.0102\n",
            "Epoch 8/100\n",
            "103/103 [==============================] - 0s 400us/step - loss: 0.0047 - val_loss: 0.0073\n",
            "Epoch 9/100\n",
            "103/103 [==============================] - 0s 377us/step - loss: 0.0031 - val_loss: 0.0054\n",
            "Epoch 10/100\n",
            "103/103 [==============================] - 0s 423us/step - loss: 0.0021 - val_loss: 0.0043\n",
            "Epoch 11/100\n",
            "103/103 [==============================] - 0s 396us/step - loss: 0.0014 - val_loss: 0.0036\n",
            "Epoch 12/100\n",
            "103/103 [==============================] - 0s 391us/step - loss: 0.0010 - val_loss: 0.0031\n",
            "Epoch 13/100\n",
            "103/103 [==============================] - 0s 390us/step - loss: 7.5538e-04 - val_loss: 0.0027\n",
            "Epoch 14/100\n",
            "103/103 [==============================] - 0s 376us/step - loss: 5.7740e-04 - val_loss: 0.0025\n",
            "Epoch 15/100\n",
            "103/103 [==============================] - 0s 375us/step - loss: 4.5360e-04 - val_loss: 0.0024\n",
            "Epoch 16/100\n",
            "103/103 [==============================] - 0s 375us/step - loss: 3.8959e-04 - val_loss: 0.0023\n",
            "Epoch 17/100\n",
            "103/103 [==============================] - 0s 438us/step - loss: 3.4695e-04 - val_loss: 0.0023\n",
            "Epoch 18/100\n",
            "103/103 [==============================] - 0s 398us/step - loss: 3.2122e-04 - val_loss: 0.0022\n",
            "Epoch 19/100\n",
            "103/103 [==============================] - 0s 377us/step - loss: 3.0610e-04 - val_loss: 0.0022\n",
            "Epoch 20/100\n",
            "103/103 [==============================] - 0s 382us/step - loss: 2.9244e-04 - val_loss: 0.0022\n",
            "Epoch 21/100\n",
            "103/103 [==============================] - 0s 385us/step - loss: 2.8483e-04 - val_loss: 0.0022\n",
            "Epoch 22/100\n",
            "103/103 [==============================] - 0s 382us/step - loss: 2.7876e-04 - val_loss: 0.0022\n",
            "Epoch 23/100\n",
            "103/103 [==============================] - 0s 372us/step - loss: 2.7453e-04 - val_loss: 0.0021\n",
            "Epoch 24/100\n",
            "103/103 [==============================] - 0s 397us/step - loss: 2.7288e-04 - val_loss: 0.0021\n",
            "Epoch 25/100\n",
            "103/103 [==============================] - 0s 388us/step - loss: 2.7003e-04 - val_loss: 0.0021\n",
            "Epoch 26/100\n",
            "103/103 [==============================] - 0s 377us/step - loss: 2.6621e-04 - val_loss: 0.0021\n",
            "Epoch 27/100\n",
            "103/103 [==============================] - 0s 395us/step - loss: 2.6516e-04 - val_loss: 0.0021\n",
            "Epoch 28/100\n",
            "103/103 [==============================] - 0s 406us/step - loss: 2.6557e-04 - val_loss: 0.0021\n",
            "Epoch 29/100\n",
            "103/103 [==============================] - 0s 353us/step - loss: 2.6433e-04 - val_loss: 0.0021\n",
            "Epoch 30/100\n",
            "103/103 [==============================] - 0s 351us/step - loss: 2.6186e-04 - val_loss: 0.0021\n",
            "Epoch 31/100\n",
            "103/103 [==============================] - 0s 467us/step - loss: 2.6000e-04 - val_loss: 0.0021\n",
            "Epoch 32/100\n",
            "103/103 [==============================] - 0s 415us/step - loss: 2.6043e-04 - val_loss: 0.0021\n",
            "Epoch 33/100\n",
            "103/103 [==============================] - 0s 379us/step - loss: 2.5821e-04 - val_loss: 0.0021\n",
            "Epoch 34/100\n",
            "103/103 [==============================] - 0s 369us/step - loss: 2.5796e-04 - val_loss: 0.0021\n",
            "Epoch 35/100\n",
            "103/103 [==============================] - 0s 383us/step - loss: 2.5553e-04 - val_loss: 0.0021\n",
            "Epoch 36/100\n",
            "103/103 [==============================] - 0s 379us/step - loss: 2.5389e-04 - val_loss: 0.0021\n",
            "Epoch 37/100\n",
            "103/103 [==============================] - 0s 366us/step - loss: 2.5277e-04 - val_loss: 0.0021\n",
            "Epoch 38/100\n",
            "103/103 [==============================] - 0s 379us/step - loss: 2.5131e-04 - val_loss: 0.0021\n",
            "Epoch 39/100\n",
            "103/103 [==============================] - 0s 362us/step - loss: 2.5047e-04 - val_loss: 0.0021\n",
            "Epoch 40/100\n",
            "103/103 [==============================] - 0s 435us/step - loss: 2.4876e-04 - val_loss: 0.0021\n",
            "Epoch 41/100\n",
            "103/103 [==============================] - 0s 358us/step - loss: 2.4880e-04 - val_loss: 0.0021\n",
            "Epoch 42/100\n",
            "103/103 [==============================] - 0s 394us/step - loss: 2.4616e-04 - val_loss: 0.0021\n",
            "Epoch 43/100\n",
            "103/103 [==============================] - 0s 392us/step - loss: 2.4573e-04 - val_loss: 0.0021\n",
            "Epoch 44/100\n",
            "103/103 [==============================] - 0s 377us/step - loss: 2.4460e-04 - val_loss: 0.0021\n",
            "Epoch 45/100\n",
            "103/103 [==============================] - 0s 373us/step - loss: 2.4265e-04 - val_loss: 0.0021\n",
            "Epoch 46/100\n",
            "103/103 [==============================] - 0s 400us/step - loss: 2.4190e-04 - val_loss: 0.0021\n",
            "Epoch 47/100\n",
            "103/103 [==============================] - 0s 396us/step - loss: 2.4065e-04 - val_loss: 0.0021\n",
            "Epoch 48/100\n",
            "103/103 [==============================] - 0s 372us/step - loss: 2.4027e-04 - val_loss: 0.0021\n",
            "Epoch 49/100\n",
            "103/103 [==============================] - 0s 395us/step - loss: 2.3862e-04 - val_loss: 0.0021\n",
            "Epoch 50/100\n",
            "103/103 [==============================] - 0s 438us/step - loss: 2.3944e-04 - val_loss: 0.0021\n",
            "Epoch 51/100\n",
            "103/103 [==============================] - 0s 400us/step - loss: 2.3596e-04 - val_loss: 0.0021\n",
            "Epoch 52/100\n",
            "103/103 [==============================] - 0s 382us/step - loss: 2.3536e-04 - val_loss: 0.0020\n",
            "Epoch 53/100\n",
            "103/103 [==============================] - 0s 427us/step - loss: 2.3348e-04 - val_loss: 0.0020\n",
            "Epoch 54/100\n",
            "103/103 [==============================] - 0s 420us/step - loss: 2.3453e-04 - val_loss: 0.0020\n",
            "Epoch 55/100\n",
            "103/103 [==============================] - 0s 388us/step - loss: 2.3277e-04 - val_loss: 0.0020\n",
            "Epoch 56/100\n",
            "103/103 [==============================] - 0s 380us/step - loss: 2.3032e-04 - val_loss: 0.0020\n",
            "Epoch 57/100\n",
            "103/103 [==============================] - 0s 367us/step - loss: 2.2892e-04 - val_loss: 0.0020\n",
            "Epoch 58/100\n",
            "103/103 [==============================] - 0s 359us/step - loss: 2.2867e-04 - val_loss: 0.0020\n",
            "Epoch 59/100\n",
            "103/103 [==============================] - 0s 434us/step - loss: 2.2786e-04 - val_loss: 0.0020\n",
            "Epoch 60/100\n",
            "103/103 [==============================] - 0s 377us/step - loss: 2.2537e-04 - val_loss: 0.0020\n",
            "Epoch 61/100\n",
            "103/103 [==============================] - 0s 357us/step - loss: 2.2799e-04 - val_loss: 0.0020\n",
            "Epoch 62/100\n",
            "103/103 [==============================] - 0s 386us/step - loss: 2.2533e-04 - val_loss: 0.0020\n",
            "Epoch 63/100\n",
            "103/103 [==============================] - 0s 354us/step - loss: 2.2255e-04 - val_loss: 0.0020\n",
            "Epoch 64/100\n",
            "103/103 [==============================] - 0s 390us/step - loss: 2.2116e-04 - val_loss: 0.0020\n",
            "Epoch 65/100\n",
            "103/103 [==============================] - 0s 387us/step - loss: 2.2013e-04 - val_loss: 0.0020\n",
            "Epoch 66/100\n",
            "103/103 [==============================] - 0s 387us/step - loss: 2.2249e-04 - val_loss: 0.0020\n",
            "Epoch 67/100\n",
            "103/103 [==============================] - 0s 388us/step - loss: 2.1910e-04 - val_loss: 0.0020\n",
            "Epoch 68/100\n",
            "103/103 [==============================] - 0s 386us/step - loss: 2.1757e-04 - val_loss: 0.0020\n",
            "Epoch 69/100\n",
            "103/103 [==============================] - 0s 432us/step - loss: 2.1624e-04 - val_loss: 0.0020\n",
            "Epoch 70/100\n",
            "103/103 [==============================] - 0s 378us/step - loss: 2.1671e-04 - val_loss: 0.0020\n",
            "Epoch 71/100\n",
            "103/103 [==============================] - 0s 373us/step - loss: 2.1411e-04 - val_loss: 0.0020\n",
            "Epoch 72/100\n",
            "103/103 [==============================] - 0s 401us/step - loss: 2.1402e-04 - val_loss: 0.0020\n",
            "Epoch 73/100\n",
            "103/103 [==============================] - 0s 372us/step - loss: 2.1253e-04 - val_loss: 0.0020\n",
            "Epoch 74/100\n",
            "103/103 [==============================] - 0s 377us/step - loss: 2.1239e-04 - val_loss: 0.0020\n",
            "Epoch 75/100\n",
            "103/103 [==============================] - 0s 380us/step - loss: 2.1117e-04 - val_loss: 0.0020\n",
            "Epoch 76/100\n",
            "103/103 [==============================] - 0s 385us/step - loss: 2.1039e-04 - val_loss: 0.0020\n",
            "Epoch 77/100\n",
            "103/103 [==============================] - 0s 376us/step - loss: 2.0722e-04 - val_loss: 0.0020\n",
            "Epoch 78/100\n",
            "103/103 [==============================] - 0s 430us/step - loss: 2.0688e-04 - val_loss: 0.0020\n",
            "Epoch 79/100\n",
            "103/103 [==============================] - 0s 393us/step - loss: 2.0581e-04 - val_loss: 0.0020\n",
            "Epoch 80/100\n",
            "103/103 [==============================] - 0s 381us/step - loss: 2.0456e-04 - val_loss: 0.0020\n",
            "Epoch 81/100\n",
            "103/103 [==============================] - 0s 388us/step - loss: 2.0469e-04 - val_loss: 0.0020\n",
            "Epoch 82/100\n",
            "103/103 [==============================] - 0s 358us/step - loss: 2.0637e-04 - val_loss: 0.0020\n",
            "Epoch 83/100\n",
            "103/103 [==============================] - 0s 356us/step - loss: 2.0261e-04 - val_loss: 0.0020\n",
            "Epoch 84/100\n",
            "103/103 [==============================] - 0s 368us/step - loss: 2.0317e-04 - val_loss: 0.0020\n",
            "Epoch 85/100\n",
            "103/103 [==============================] - 0s 363us/step - loss: 2.0153e-04 - val_loss: 0.0020\n",
            "Epoch 86/100\n",
            "103/103 [==============================] - 0s 361us/step - loss: 1.9955e-04 - val_loss: 0.0020\n",
            "Epoch 87/100\n",
            "103/103 [==============================] - 0s 362us/step - loss: 1.9796e-04 - val_loss: 0.0020\n",
            "Epoch 88/100\n",
            "103/103 [==============================] - 0s 368us/step - loss: 1.9780e-04 - val_loss: 0.0020\n",
            "Epoch 89/100\n",
            "103/103 [==============================] - 0s 362us/step - loss: 1.9628e-04 - val_loss: 0.0020\n",
            "Epoch 90/100\n",
            "103/103 [==============================] - 0s 369us/step - loss: 1.9732e-04 - val_loss: 0.0019\n",
            "Epoch 91/100\n",
            "103/103 [==============================] - 0s 368us/step - loss: 1.9536e-04 - val_loss: 0.0019\n",
            "Epoch 92/100\n",
            "103/103 [==============================] - 0s 370us/step - loss: 1.9369e-04 - val_loss: 0.0019\n",
            "Epoch 93/100\n",
            "103/103 [==============================] - 0s 369us/step - loss: 1.9366e-04 - val_loss: 0.0019\n",
            "Epoch 94/100\n",
            "103/103 [==============================] - 0s 359us/step - loss: 1.9223e-04 - val_loss: 0.0019\n",
            "Epoch 95/100\n",
            "103/103 [==============================] - 0s 397us/step - loss: 1.9092e-04 - val_loss: 0.0019\n",
            "Epoch 96/100\n",
            "103/103 [==============================] - 0s 388us/step - loss: 1.8994e-04 - val_loss: 0.0019\n",
            "Epoch 97/100\n",
            "103/103 [==============================] - 0s 389us/step - loss: 1.8999e-04 - val_loss: 0.0019\n",
            "Epoch 98/100\n",
            "103/103 [==============================] - 0s 369us/step - loss: 1.8755e-04 - val_loss: 0.0019\n",
            "Epoch 99/100\n",
            "103/103 [==============================] - 0s 389us/step - loss: 1.8684e-04 - val_loss: 0.0019\n",
            "Epoch 100/100\n",
            "103/103 [==============================] - 0s 361us/step - loss: 1.8563e-04 - val_loss: 0.0019\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls-YgDbEIpR0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}